---
date: 2023-12-22
title: "A Survey of Generative AI for Cybersecurity: Potential, Pitfalls, and Prospects"
category: Cybersecurity
type: Paper
language: English
tldr:
- 생성형 AI(GenAI)가 사이버 보안 분야에서 갖는 공격과 방어의 양면성을 체계적으로 분석한 서베이 논문입니다.
- 피싱, 악성코드 생성 등의 공격 시나리오와 취약점 탐지, 위협 분석 등의 방어적 활용 사례를 구체적으로 제시합니다.
- GenAI 모델 고유의 보안 취약점과 프라이버시 문제를 해결하기 위한 기술적 가이드라인 및 미래 연구 방향을 제안합니다.
tags:
- generative_ai
- cybersecurity
- llm
- ai_security
- machine_learning
source: https://ieeexplore.ieee.org/abstract/document/10391266
country: China
institute: Huazhong University of Science and Technology
authors:
- Shiduo Deng
- Wenbo Jiang
- Zeyu Wu
- Wei Huang
- Shui Yu
correspondingAuthor: Wenbo Jiang
---

# A Survey of Generative AI for Cybersecurity: Potential, Pitfalls, and Prospects

이 논문은 생성형 AI(GenAI) 기술이 사이버 보안의 지형을 어떻게 변화시키고 있는지 조사하며, 공격자와 방어자 모두에게 주어지는 기회와 위험 요소를 심도 있게 다룹니다.

* **이중적 활용성 분석**: GenAI가 고도화된 피싱 메일 작성 및 다형성 악성코드 생성 등 공격 도구로 악용될 수 있는 위험성과 동시에, 보안 관제 및 위협 탐지 자동화를 위한 방어 도구로서의 잠재력을 동시에 분석합니다.
* **공격 시나리오 구체화**: 사회 공학적 공격, 취약점 자동 탐색, CAPTCHA 우회 등 생성형 모델을 통해 자동화되고 정교해진 최신 사이버 공격 기법들을 분류하고 설명합니다.
* **방어적 응용 사례**: 대규모 언어 모델(LLM)을 활용한 보안 로그 분석, 악성코드 역공학 지원, 침입 탐지 시스템(IDS)의 성능 향상 및 보안 정책 자동 생성 방안을 제시합니다.
* **GenAI 모델 자체의 취약점**: 프롬프트 인젝션(Prompt Injection), 학습 데이터 오염(Data Poisoning), 모델 추출 공격 등 AI 모델이 직면한 고유한 보안 위협 요소들을 정의합니다.
* **프라이버시 및 데이터 보안**: 모델 학습 과정에서 발생할 수 있는 민감 정보 유출 문제와 이를 방지하기 위한 차분 프라이버시(Differential Privacy) 및 연합 학습(Federated Learning)의 적용 가능성을 논의합니다.
* **미래 연구 과제**: 설명 가능한 AI(XAI)를 통한 보안 의사결정의 신뢰도 향상, 공격과 방어의 기술적 군비 경쟁 속에서 인간-AI 협업 보안 모델의 필요성을 강조합니다.